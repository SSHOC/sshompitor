name: Weekly Full API Dump

on:
  schedule:
    - cron: '0 3 * * 1'  # Every Monday at 3:00 AM UTC
  workflow_dispatch:

jobs:
  collect-full-data:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Install jq
        run: sudo apt-get update && sudo apt-get install -y jq

      - name: Fetch and store full API data
        run: |
          TIMESTAMP=$(date +%s)
          mkdir -p "$GITHUB_WORKSPACE/data"

          declare -A ENDPOINTS=(
            ["tools-services"]="https://marketplace-api.sshopencloud.eu/api/tools-services"
            ["training-materials"]="https://marketplace-api.sshopencloud.eu/api/training-materials"
            ["publications"]="https://marketplace-api.sshopencloud.eu/api/publications"
            ["datasets"]="https://marketplace-api.sshopencloud.eu/api/datasets"
            ["workflows"]="https://marketplace-api.sshopencloud.eu/api/workflows"
          )

          declare -A RESPONSE_KEYS=(
            ["tools-services"]="toolsServices"
            ["training-materials"]="trainingMaterials"
            ["publications"]="publications"
            ["datasets"]="datasets"
            ["workflows"]="workflows"
          )

          COMBINED_JSON="{}"

          for CATEGORY in "${!ENDPOINTS[@]}"; do
            BASE_URL="${ENDPOINTS[$CATEGORY]}"
            RESPONSE_KEY="${RESPONSE_KEYS[$CATEGORY]}"

            FIRST_PAGE=$(curl -s "${BASE_URL}?page=1")
            TOTAL_PAGES=$(echo "$FIRST_PAGE" | jq -r '.pages // 1')

            TMP_DIR="/tmp/category_${CATEGORY}_$RANDOM"
            mkdir -p "$TMP_DIR"
            ITEMS_FILE="$TMP_DIR/items.json"
            METADATA_FILE="$TMP_DIR/meta.json"

            echo "$FIRST_PAGE" | jq "del(.${RESPONSE_KEY})" > "$METADATA_FILE"
            echo "[" > "$ITEMS_FILE"

            FIRST=true
            echo "$FIRST_PAGE" | jq -c ".${RESPONSE_KEY}[]" | while IFS= read -r item; do
              if [ "$FIRST" = true ]; then
                echo "$item" >> "$ITEMS_FILE"
                FIRST=false
              else
                echo "," >> "$ITEMS_FILE"
                echo "$item" >> "$ITEMS_FILE"
              fi
            done

            for ((i = 2; i <= TOTAL_PAGES; i++)); do
              PAGE_DATA=$(curl -s "${BASE_URL}?page=${i}")
              PAGE_ITEMS=$(echo "$PAGE_DATA" | jq -c ".${RESPONSE_KEY}[]")
              while IFS= read -r item; do
                echo "," >> "$ITEMS_FILE"
                echo "$item" >> "$ITEMS_FILE"
              done <<< "$PAGE_ITEMS"
            done

            echo "]" >> "$ITEMS_FILE"
            RESPONSE=$(jq -s '.[0] + {items: .[1]}' "$METADATA_FILE" "$ITEMS_FILE")

            COMBINED_JSON=$(jq --argjson newData "$RESPONSE" --arg key "$CATEGORY" '. + {($key): $newData}' <<< "$COMBINED_JSON")
          done

          echo "$COMBINED_JSON" > "$GITHUB_WORKSPACE/data/tmp_combined.json"
          jq -n --arg ts "$TIMESTAMP" --argfile data "$GITHUB_WORKSPACE/data/tmp_combined.json" '{($ts): $data[0]}' > "$GITHUB_WORKSPACE/data/full_items.json"

      - name: Commit full_items.json
        run: |
          git config user.name "github-actions"
          git config user.email "github-actions@github.com"
          git add data/full_items.json
          git commit -m "Weekly full_items.json update: $(date -u)" || echo "No changes to commit"
          git push
